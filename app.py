import os
import fitz  # PyMuPDF
import streamlit as st
from groq import Groq
from transformers import BertTokenizer, BertModel
import torch
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import os
from key import api_key

# API AnahtarÄ±nÄ± buraya ekleyin
PDF_FOLDER = "pdf_files"

# Streamlit ArayÃ¼zÃ¼
st.title("ğŸ“„ AkÄ±llÄ± PDF Arama & Soru Cevaplama")

# PDF YÃ¼kleme
uploaded_files = st.file_uploader("PDF DosyalarÄ±nÄ± YÃ¼kleyin", accept_multiple_files=True, type=["pdf"])

def extract_text_from_pdf(file):
    text = ""
    with fitz.open(stream=file.read()) as doc:
        for page in doc:
            text += page.get_text()
    return text

# PDF'leri kaydet ve iÅŸleme al
pdf_texts = {}
if uploaded_files:
    os.makedirs(PDF_FOLDER, exist_ok=True)
    for file in uploaded_files:
        file_path = os.path.join(PDF_FOLDER, file.name)
        with open(file_path, "wb") as f:
            f.write(file.read())
        pdf_texts[file.name] = extract_text_from_pdf(file)

# Daha Ã¶nce kaydedilmiÅŸ PDF'leri oku
for file_name in os.listdir(PDF_FOLDER):
    if file_name.endswith(".pdf") and file_name not in pdf_texts:
        pdf_path = os.path.join(PDF_FOLDER, file_name)
        with open(pdf_path, "rb") as f:
            pdf_texts[file_name] = extract_text_from_pdf(f)

# KullanÄ±cÄ±dan soru al
query = st.text_input("ğŸ” Bir soru girin")

if query:
    # BERT modelini yÃ¼kle
    model_name = "bert-base-uncased"
    tokenizer = BertTokenizer.from_pretrained(model_name)
    model = BertModel.from_pretrained(model_name)

    def get_embedding(text):
        inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=512)
        with torch.no_grad():
            outputs = model(**inputs)
        return outputs.last_hidden_state.mean(dim=1).numpy()

    # PDF iÃ§eriklerini embedding'e Ã§evir
    pdf_embeddings = {file: get_embedding(content) for file, content in pdf_texts.items()}
    
    # Soruyu embedding'e Ã§evir
    query_embedding = get_embedding(query)

    # Cosine Similarity hesapla
    similarities = {file: cosine_similarity(query_embedding, emb)[0][0] for file, emb in pdf_embeddings.items()}
    
    # En benzer PDF'yi seÃ§
    most_similar_pdf = max(similarities, key=similarities.get)
    
    st.subheader(f"ğŸ“„ En alakalÄ± PDF: {most_similar_pdf}")
    st.write(f"ğŸ“Š Benzerlik Skoru: {similarities[most_similar_pdf]:.4f}")
    st.text_area("ğŸ” PDF Ä°Ã§eriÄŸi (Ä°lk 500 karakter)", pdf_texts[most_similar_pdf][:500])
    
    # Groq istemcisini baÅŸlat
   
    client = Groq(
    api_key= api_key )
    # PDF Ã¶zetleme
    context = pdf_texts[most_similar_pdf][:2000]
    summary_prompt = f"Context: {context}\nPlease summarize the above text in a short and concise paragraph, highlighting the key points."
    
    summary_response = client.chat.completions.create(
        messages=[{"role": "user", "content": summary_prompt}],
        model="llama3-70b-8192"
    )
    
    summary = summary_response.choices[0].message.content
    st.subheader("ğŸ“œ PDF Ã–zeti")
    st.write(summary)
    
    # Soruyu cevaplama
    qa_prompt = f"Context: {summary}\nQuestion: {query}\nAnswer:"
    qa_response = client.chat.completions.create(
        messages=[{"role": "user", "content": qa_prompt}],
        model="llama3-70b-8192"
    )
    
    qa_answer = qa_response.choices[0].message.content
    st.subheader("ğŸ“œ Cevap")
    st.write(qa_answer)
